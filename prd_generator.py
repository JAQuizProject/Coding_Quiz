#!/usr/bin/env python3
"""
PRD ìë™ ìƒì„±ê¸°
ì½”ë“œë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ Product Requirements Documentë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import re
import json
import ast
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

class CodebaseAnalyzer:
    """ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.analysis_result = {
            'project_info': {},
            'tech_stack': {},
            'models': {},
            'apis': {},
            'features': {},
            'security': {},
            'database': {}
        }

    def analyze_project_structure(self):
        """í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„"""
        backend_path = self.project_root / 'backend'
        frontend_path = self.project_root / 'frontend'

        # ë°±ì—”ë“œ ë¶„ì„
        if backend_path.exists():
            self.analysis_result['tech_stack']['backend'] = self._analyze_backend(backend_path)
            self.analysis_result['models'] = self._extract_models(backend_path)
            self.analysis_result['apis'] = self._extract_apis(backend_path)
            self.analysis_result['database'] = self._analyze_database(backend_path)

        # í”„ë¡ íŠ¸ì—”ë“œ ë¶„ì„
        if frontend_path.exists():
            self.analysis_result['tech_stack']['frontend'] = self._analyze_frontend(frontend_path)
            self.analysis_result['features'] = self._extract_frontend_features(frontend_path)

    def _analyze_backend(self, backend_path: Path) -> Dict:
        """ë°±ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"""
        requirements_file = backend_path / 'requirements.txt'
        main_file = backend_path / 'main.py'

        tech_stack = {
            'framework': 'FastAPI',
            'dependencies': [],
            'database_orm': 'SQLAlchemy',
            'authentication': 'JWT + bcrypt'
        }

        if requirements_file.exists():
            with open(requirements_file, 'r', encoding='utf-8') as f:
                tech_stack['dependencies'] = [line.strip() for line in f if line.strip() and not line.startswith('#')]

        return tech_stack

    def _analyze_frontend(self, frontend_path: Path) -> Dict:
        """í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"""
        package_json = frontend_path / 'package.json'

        tech_stack = {
            'framework': 'Next.js',
            'ui_library': 'React Bootstrap',
            'dependencies': []
        }

        if package_json.exists():
            with open(package_json, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
                tech_stack['dependencies'] = list(package_data.get('dependencies', {}).keys())
                tech_stack['version'] = package_data.get('version', '1.0.0')

        return tech_stack

    def _extract_models(self, backend_path: Path) -> Dict:
        """ë°ì´í„° ëª¨ë¸ ì¶”ì¶œ"""
        models = {}
        models_path = backend_path / 'app' / 'models'

        if models_path.exists():
            for model_file in models_path.glob('*.py'):
                if model_file.name == '__init__.py':
                    continue

                model_name = model_file.stem
                models[model_name] = self._parse_model_file(model_file)

        return models

    def _parse_model_file(self, model_file: Path) -> Dict:
        """ëª¨ë¸ íŒŒì¼ íŒŒì‹±"""
        with open(model_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # SQLAlchemy ëª¨ë¸ íŒŒì‹±
        model_info = {
            'table_name': '',
            'fields': [],
            'relationships': []
        }

        # í…Œì´ë¸”ëª… ì¶”ì¶œ
        table_match = re.search(r'__tablename__\s*=\s*["\']([^"\']+)["\']', content)
        if table_match:
            model_info['table_name'] = table_match.group(1)

        # ì»¬ëŸ¼ ì¶”ì¶œ
        column_pattern = r'(\w+)\s*=\s*Column\([^)]+\)'
        columns = re.findall(column_pattern, content)
        model_info['fields'] = columns

        return model_info

    def _extract_apis(self, backend_path: Path) -> Dict:
        """API ì—”ë“œí¬ì¸íŠ¸ ì¶”ì¶œ"""
        apis = {}
        routes_path = backend_path / 'app' / 'routes'

        if routes_path.exists():
            for route_file in routes_path.glob('*.py'):
                if route_file.name == '__init__.py':
                    continue

                route_name = route_file.stem
                apis[route_name] = self._parse_route_file(route_file)

        return apis

    def _parse_route_file(self, route_file: Path) -> List[Dict]:
        """ë¼ìš°íŠ¸ íŒŒì¼ íŒŒì‹±"""
        with open(route_file, 'r', encoding='utf-8') as f:
            content = f.read()

        endpoints = []

        # FastAPI ë¼ìš°í„° íŒ¨í„´ ë§¤ì¹­
        route_pattern = r'@router\.(get|post|put|delete)\(["\']([^"\']+)["\']\)\s*\n\s*async def (\w+)'
        matches = re.findall(route_pattern, content, re.MULTILINE)

        for method, path, function_name in matches:
            endpoints.append({
                'method': method.upper(),
                'path': path,
                'function_name': function_name,
                'description': self._extract_function_docstring(content, function_name)
            })

        return endpoints

    def _extract_function_docstring(self, content: str, function_name: str) -> str:
        """í•¨ìˆ˜ docstring ì¶”ì¶œ"""
        pattern = rf'async def {function_name}[^:]*:\s*\n\s*"""(.*?)"""'
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else ""

    def _analyze_database(self, backend_path: Path) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¶„ì„"""
        config_file = backend_path / 'app' / 'core' / 'config.py'
        database_file = backend_path / 'app' / 'core' / 'database.py'

        db_info = {
            'type': 'SQLite/PostgreSQL',
            'orm': 'SQLAlchemy',
            'migration': False
        }

        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'postgresql' in content.lower():
                    db_info['type'] = 'PostgreSQL'
                elif 'sqlite' in content.lower():
                    db_info['type'] = 'SQLite'

        return db_info

    def _extract_frontend_features(self, frontend_path: Path) -> Dict:
        """í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŠ¥ ì¶”ì¶œ"""
        features = {}
        app_path = frontend_path / 'app'

        if app_path.exists():
            for page_dir in app_path.iterdir():
                if page_dir.is_dir() and not page_dir.name.startswith('.'):
                    page_name = page_dir.name
                    features[page_name] = {
                        'path': f'/{page_name}',
                        'description': self._extract_page_description(page_dir)
                    }

        return features

    def _extract_page_description(self, page_dir: Path) -> str:
        """í˜ì´ì§€ ì„¤ëª… ì¶”ì¶œ"""
        page_file = page_dir / 'page.js'
        if page_file.exists():
            with open(page_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # ê°„ë‹¨í•œ ì„¤ëª… ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
                return f"React ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ {page_dir.name} í˜ì´ì§€"
        return ""

class PRDGenerator:
    """PRD ìƒì„±ê¸° í´ë˜ìŠ¤"""

    def __init__(self, analysis_result: Dict):
        self.analysis = analysis_result

    def generate_prd(self) -> str:
        """PRD ìƒì„±"""
        prd_content = f"""# ì½”ë”© í€´ì¦ˆ í”Œë«í¼ PRD (Product Requirements Document)

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ë²„ì „**: v1.0
- **ì‘ì„±ì¼**: {datetime.now().strftime('%Y-%m-%d')}
- **ì‘ì„±ì**: PRD Generator
- **ë§ˆì§€ë§‰ ìˆ˜ì •**: {datetime.now().strftime('%Y-%m-%d')}

## ğŸ¯ 1. ì œí’ˆ ê°œìš”
### 1.1 ì œí’ˆëª…
ì½”ë”© ë©´ì ‘ ëŒ€ë¹„ í€´ì¦ˆ í”Œë«í¼

### 1.2 ì œí’ˆ ë¹„ì „
ê¸°ìˆ  ë©´ì ‘ì„ ì¤€ë¹„í•˜ëŠ” ê°œë°œìë“¤ì„ ìœ„í•œ ì‹¤ì „í˜• ì½”ë”© í€´ì¦ˆ í”Œë«í¼

### 1.3 í•µì‹¬ ê°€ì¹˜
- ì‹¤ì „ ì¤‘ì‹¬ì˜ ë¬¸ì œ ì œê³µ
- ì¦‰ì‹œ í”¼ë“œë°± ë° ìƒì„¸ í•´ì„¤
- ì§„ë„ ê´€ë¦¬ ë° ì„±ì·¨ë„ ì¶”ì 
- ê²½ìŸ í•™ìŠµì„ í†µí•œ ë™ê¸°ë¶€ì—¬

## ğŸ—ï¸ 2. ê¸°ìˆ  ìŠ¤íƒ
### 2.1 ë°±ì—”ë“œ
- **Framework**: {self.analysis['tech_stack']['backend']['framework']}
- **ORM**: {self.analysis['tech_stack']['backend']['database_orm']}
- **Authentication**: {self.analysis['tech_stack']['backend']['authentication']}
- **Dependencies**: {', '.join(self.analysis['tech_stack']['backend']['dependencies'])}

### 2.2 í”„ë¡ íŠ¸ì—”ë“œ
- **Framework**: {self.analysis['tech_stack']['frontend']['framework']}
- **UI Library**: {self.analysis['tech_stack']['frontend']['ui_library']}
- **Dependencies**: {', '.join(self.analysis['tech_stack']['frontend']['dependencies'])}

### 2.3 ë°ì´í„°ë² ì´ìŠ¤
- **Type**: {self.analysis['database']['type']}
- **ORM**: {self.analysis['database']['orm']}

## âš™ï¸ 3. í•µì‹¬ ê¸°ëŠ¥
{self._generate_features_section()}

## ğŸ“Š 4. ë°ì´í„° ëª¨ë¸
{self._generate_models_section()}

## ğŸ”Œ 5. API ëª…ì„¸
{self._generate_api_section()}

## ğŸ¨ 6. ì‚¬ìš©ì ê²½í—˜
{self._generate_ux_section()}

## ğŸ”’ 7. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
### 7.1 ì¸ì¦/ì¸ê°€
- JWT í† í° ê¸°ë°˜ ì¸ì¦
- bcryptë¥¼ í†µí•œ ë¹„ë°€ë²ˆí˜¸ í•´ì‹±
- í† í° ë§Œë£Œ ì‹œê°„ ê´€ë¦¬

### 7.2 ë°ì´í„° ë³´ì•ˆ
- SQL Injection ë°©ì§€ (SQLAlchemy ORM ì‚¬ìš©)
- CORS ì •ì±… ì ìš©
- í™˜ê²½ë³„ ë„ë©”ì¸ ì œí•œ

## ğŸ“ˆ 8. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
### 8.1 ì‘ë‹µ ì‹œê°„
- API ì‘ë‹µ ì‹œê°„: 200ms ì´í•˜
- í˜ì´ì§€ ë¡œë”© ì‹œê°„: 2ì´ˆ ì´í•˜

### 8.2 ë™ì‹œì„±
- ë™ì‹œ ì‚¬ìš©ì: 100ëª… ì´ìƒ ì§€ì›
- ë¹„ë™ê¸° ì²˜ë¦¬ (FastAPI async/await)

## ğŸš€ 9. ë°°í¬ ë° ìš´ì˜
### 9.1 í™˜ê²½ êµ¬ì„±
- Docker ì»¨í…Œì´ë„ˆí™”
- í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬

### 9.2 ëª¨ë‹ˆí„°ë§
- ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- ì—ëŸ¬ ë¡œê¹… ë° ì¶”ì 

## ğŸ“… 10. ê°œë°œ ë¡œë“œë§µ
### 10.1 Phase 1 (1-3ê°œì›”)
- ê¸°ë³¸ í€´ì¦ˆ ê¸°ëŠ¥ ì™„ì„±
- ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•

### 10.2 Phase 2 (3-6ê°œì›”)
- ë­í‚¹ ì‹œìŠ¤í…œ êµ¬í˜„
- ì„±ëŠ¥ ìµœì í™”

### 10.3 Phase 3 (6-12ê°œì›”)
- ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€
- ëª¨ë°”ì¼ ì§€ì›

## ğŸ“Š 11. ì„±ê³µ ì§€í‘œ (KPI)
### 11.1 ì‚¬ìš©ì ì§€í‘œ
- ì¼ì¼ í™œì„± ì‚¬ìš©ì (DAU)
- ì›”ê°„ í™œì„± ì‚¬ìš©ì (MAU)

### 11.2 ê¸°ìˆ  ì§€í‘œ
- API ì‘ë‹µ ì‹œê°„
- ì‹œìŠ¤í…œ ê°€ìš©ì„±
- ì—ëŸ¬ ë°œìƒë¥ 
"""
        return prd_content

    def _generate_features_section(self) -> str:
        """ê¸°ëŠ¥ ì„¹ì…˜ ìƒì„±"""
        features = []
        for page_name, page_info in self.analysis['features'].items():
            features.append(f"### 3.{len(features)+1} {page_name.title()} ê¸°ëŠ¥")
            features.append(f"- **ì„¤ëª…**: {page_info['description']}")
            features.append(f"- **ê²½ë¡œ**: {page_info['path']}")
            features.append("")
        return "\n".join(features)

    def _generate_models_section(self) -> str:
        """ëª¨ë¸ ì„¹ì…˜ ìƒì„±"""
        models = []
        for model_name, model_info in self.analysis['models'].items():
            models.append(f"### 4.{len(models)+1} {model_name.title()}")
            models.append(f"- **í…Œì´ë¸”ëª…**: {model_info['table_name']}")
            models.append(f"- **í•„ë“œ**: {', '.join(model_info['fields'])}")
            models.append("")
        return "\n".join(models)

    def _generate_api_section(self) -> str:
        """API ì„¹ì…˜ ìƒì„±"""
        apis = []
        for route_name, endpoints in self.analysis['apis'].items():
            apis.append(f"### 5.{len(apis)+1} {route_name.title()} API")
            for endpoint in endpoints:
                apis.append(f"- `{endpoint['method']} {endpoint['path']}` - {endpoint['description']}")
            apis.append("")
        return "\n".join(apis)

    def _generate_ux_section(self) -> str:
        """UX ì„¹ì…˜ ìƒì„±"""
        ux = []
        for page_name, page_info in self.analysis['features'].items():
            ux.append(f"### 6.{len(ux)+1} {page_name.title()} í˜ì´ì§€")
            ux.append(f"- **ëª©ì **: {page_info['description']}")
            ux.append(f"- **ì£¼ìš” ê¸°ëŠ¥**: ì‚¬ìš©ì ì¸í„°ë™ì…˜ ë° ë°ì´í„° í‘œì‹œ")
            ux.append("")
        return "\n".join(ux)

def main():
    parser = argparse.ArgumentParser(description='PRD ìë™ ìƒì„±ê¸°')
    parser.add_argument('--project-root', default='.', help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', default='PRD.md', help='ì¶œë ¥ íŒŒì¼ëª…')

    args = parser.parse_args()

    # ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
    analyzer = CodebaseAnalyzer(args.project_root)
    analyzer.analyze_project_structure()

    # PRD ìƒì„±
    generator = PRDGenerator(analyzer.analysis_result)
    prd_content = generator.generate_prd()

    # íŒŒì¼ ì €ì¥
    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(prd_content)

    print(f"PRDê°€ {args.output}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ë¶„ì„ëœ ëª¨ë¸ ìˆ˜: {len(analyzer.analysis_result['models'])}")
    print(f"ë¶„ì„ëœ API ìˆ˜: {sum(len(apis) for apis in analyzer.analysis_result['apis'].values())}")

if __name__ == "__main__":
    main()
