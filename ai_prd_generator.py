#!/usr/bin/env python3
"""
AI ê¸°ë°˜ PRD ìƒì„±ê¸°
LangChainì„ ì‚¬ìš©í•˜ì—¬ ì§€ëŠ¥ì ì¸ PRD ìë™ ìƒì„±ê¸°
"""

import os
import json
import re
import ast
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

# LangChain imports
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class CodebaseAnalyzer:
    """ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ í´ë˜ìŠ¤ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.analysis_result = {
            'project_info': {},
            'tech_stack': {},
            'models': {},
            'apis': {},
            'features': {},
            'project_type': 'unknown',
            'business_domain': 'unknown',
            'confidence': 0.0
        }

    def analyze_project(self):
        """í”„ë¡œì íŠ¸ ì „ì²´ ë¶„ì„"""
        self._detect_project_type()
        self._analyze_tech_stack()
        self._extract_models()
        self._extract_apis()
        self._extract_features()
        self._analyze_business_domain()
        self._calculate_confidence()

    def _detect_project_type(self):
        """í”„ë¡œì íŠ¸ íƒ€ì… ìë™ ê°ì§€"""
        project_type = 'unknown'
        confidence = 0.0

        if self._has_file('backend/requirements.txt') and self._has_file('frontend/package.json'):
            confidence += 0.8
            if self._has_file('backend/main.py'):
                if self._search_in_file('backend/main.py', 'FastAPI'):
                    project_type = 'fastapi_nextjs_fullstack'
                    confidence += 0.2
                else:
                    project_type = 'python_nextjs_fullstack'
            elif self._has_file('backend/app.py'):
                project_type = 'flask_nextjs_fullstack'
            else:
                project_type = 'python_nextjs_fullstack'

        elif self._has_file('package.json'):
            confidence += 0.6
            if self._has_file('next.config.js') or self._has_file('next.config.mjs'):
                project_type = 'nextjs_webapp'
                confidence += 0.3
            elif self._has_file('src/App.js') or self._has_file('src/App.jsx'):
                project_type = 'react_webapp'
                confidence += 0.2

        elif self._has_file('requirements.txt'):
            confidence += 0.7
            if self._has_file('main.py'):
                if self._search_in_file('main.py', 'FastAPI'):
                    project_type = 'fastapi_backend'
                    confidence += 0.2
                elif self._search_in_file('main.py', 'Flask'):
                    project_type = 'flask_backend'
                    confidence += 0.2
                else:
                    project_type = 'python_backend'

        self.analysis_result['project_type'] = project_type
        self.analysis_result['confidence'] = confidence

    def _analyze_tech_stack(self):
        """ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„"""
        tech_stack = {
            'backend': {},
            'frontend': {},
            'database': {},
            'infrastructure': {}
        }

        tech_stack['backend'] = self._analyze_backend()
        tech_stack['frontend'] = self._analyze_frontend()
        tech_stack['database'] = self._analyze_database()
        tech_stack['infrastructure'] = self._analyze_infrastructure()

        self.analysis_result['tech_stack'] = tech_stack

    def _analyze_backend(self) -> Dict:
        """ë°±ì—”ë“œ ë¶„ì„"""
        backend_info = {
            'language': 'Unknown',
            'framework': 'Unknown',
            'dependencies': [],
            'patterns': []
        }

        if self._has_file('backend/requirements.txt') or self._has_file('requirements.txt'):
            backend_info['language'] = 'Python'
            req_file = 'backend/requirements.txt' if self._has_file('backend/requirements.txt') else 'requirements.txt'

            try:
                with open(self.project_root / req_file, 'r', encoding='utf-8') as f:
                    dependencies = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                    backend_info['dependencies'] = dependencies

                    if any('fastapi' in dep.lower() for dep in dependencies):
                        backend_info['framework'] = 'FastAPI'
                    elif any('flask' in dep.lower() for dep in dependencies):
                        backend_info['framework'] = 'Flask'
                    elif any('django' in dep.lower() for dep in dependencies):
                        backend_info['framework'] = 'Django'

                    if any('sqlalchemy' in dep.lower() for dep in dependencies):
                        backend_info['patterns'].append('ORM')
                    if any('jwt' in dep.lower() or 'pyjwt' in dep.lower() for dep in dependencies):
                        backend_info['patterns'].append('JWT Authentication')
                    if any('bcrypt' in dep.lower() or 'passlib' in dep.lower() for dep in dependencies):
                        backend_info['patterns'].append('Password Hashing')
            except Exception as e:
                print(f"ë°±ì—”ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")

        return backend_info

    def _analyze_frontend(self) -> Dict:
        """í”„ë¡ íŠ¸ì—”ë“œ ë¶„ì„"""
        frontend_info = {
            'framework': 'Unknown',
            'ui_library': 'Unknown',
            'dependencies': [],
            'patterns': []
        }

        package_file = 'frontend/package.json' if self._has_file('frontend/package.json') else 'package.json'

        if self._has_file(package_file):
            try:
                with open(self.project_root / package_file, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                    dependencies = package_data.get('dependencies', {})
                    dev_dependencies = package_data.get('devDependencies', {})
                    all_deps = {**dependencies, **dev_dependencies}

                    frontend_info['dependencies'] = list(dependencies.keys())

                    if 'next' in all_deps:
                        frontend_info['framework'] = 'Next.js'
                        frontend_info['patterns'].append('SSR/SSG')
                    elif 'react' in all_deps:
                        frontend_info['framework'] = 'React'
                        frontend_info['patterns'].append('SPA')
                    elif 'vue' in all_deps:
                        frontend_info['framework'] = 'Vue.js'
                        frontend_info['patterns'].append('SPA')
                    elif 'angular' in all_deps:
                        frontend_info['framework'] = 'Angular'
                        frontend_info['patterns'].append('SPA')

                    if 'react-bootstrap' in all_deps:
                        frontend_info['ui_library'] = 'React Bootstrap'
                    elif 'antd' in all_deps:
                        frontend_info['ui_library'] = 'Ant Design'
                    elif 'material-ui' in all_deps or '@mui/material' in all_deps:
                        frontend_info['ui_library'] = 'Material-UI'
                    elif 'bootstrap' in all_deps:
                        frontend_info['ui_library'] = 'Bootstrap'
                    elif 'tailwindcss' in all_deps:
                        frontend_info['ui_library'] = 'Tailwind CSS'

                    if 'axios' in all_deps:
                        frontend_info['patterns'].append('HTTP Client')
                    if 'redux' in all_deps or 'zustand' in all_deps:
                        frontend_info['patterns'].append('State Management')
                    if 'typescript' in all_deps:
                        frontend_info['patterns'].append('TypeScript')

            except Exception as e:
                print(f"í”„ë¡ íŠ¸ì—”ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")

        return frontend_info

    def _analyze_database(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„"""
        db_info = {
            'type': 'Unknown',
            'orm': 'Unknown',
            'patterns': []
        }

        config_files = [
            'backend/config.py', 'backend/settings.py', 'backend/database.py',
            'backend/app.py', 'backend/main.py', 'backend/app/core/database.py',
            'config.py', 'settings.py', 'database.py', 'app.py', 'main.py'
        ]

        for config_file in config_files:
            if self._has_file(config_file):
                try:
                    with open(self.project_root / config_file, 'r', encoding='utf-8') as f:
                        content = f.read().lower()

                        if 'postgresql' in content or 'postgres' in content:
                            db_info['type'] = 'PostgreSQL'
                        elif 'mysql' in content:
                            db_info['type'] = 'MySQL'
                        elif 'sqlite' in content:
                            db_info['type'] = 'SQLite'
                        elif 'mongodb' in content or 'mongo' in content:
                            db_info['type'] = 'MongoDB'
                        elif 'redis' in content:
                            db_info['type'] = 'Redis'

                        if 'sqlalchemy' in content:
                            db_info['orm'] = 'SQLAlchemy'
                        elif 'django' in content and 'orm' in content:
                            db_info['orm'] = 'Django ORM'
                        elif 'sequelize' in content:
                            db_info['orm'] = 'Sequelize'
                        elif 'prisma' in content:
                            db_info['orm'] = 'Prisma'

                        if 'migration' in content:
                            db_info['patterns'].append('Database Migration')
                        if 'connection' in content and 'pool' in content:
                            db_info['patterns'].append('Connection Pooling')

                except Exception as e:
                    print(f"ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")
                    continue

        return db_info

    def _analyze_infrastructure(self) -> Dict:
        """ì¸í”„ë¼ ë¶„ì„"""
        infra_info = {
            'containerization': 'None',
            'deployment': 'Unknown',
            'monitoring': 'None',
            'patterns': []
        }

        if self._has_file('Dockerfile'):
            infra_info['containerization'] = 'Docker'
            infra_info['patterns'].append('Containerization')
        elif self._has_file('docker-compose.yml') or self._has_file('docker-compose.yaml'):
            infra_info['containerization'] = 'Docker Compose'
            infra_info['patterns'].append('Multi-container')

        if self._has_file('.github/workflows'):
            infra_info['deployment'] = 'GitHub Actions'
            infra_info['patterns'].append('CI/CD')
        elif self._has_file('.gitlab-ci.yml'):
            infra_info['deployment'] = 'GitLab CI'
            infra_info['patterns'].append('CI/CD')
        elif self._has_file('Jenkinsfile'):
            infra_info['deployment'] = 'Jenkins'
            infra_info['patterns'].append('CI/CD')

        return infra_info

    def _analyze_business_domain(self):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ ë¶„ì„"""
        domain_keywords = {
            'education': ['quiz', 'course', 'lesson', 'student', 'teacher', 'learning', 'question', 'answer', 'score', 'ranking', 'exam', 'test'],
            'ecommerce': ['shop', 'cart', 'order', 'product', 'payment', 'checkout', 'buy', 'sell', 'inventory', 'customer'],
            'social': ['user', 'post', 'comment', 'like', 'follow', 'feed', 'message', 'chat', 'friend'],
            'finance': ['account', 'transaction', 'balance', 'wallet', 'bank', 'money', 'currency', 'investment'],
            'healthcare': ['patient', 'doctor', 'appointment', 'medical', 'health', 'clinic', 'hospital', 'prescription'],
            'gaming': ['game', 'player', 'level', 'achievement', 'play', 'score', 'leaderboard', 'quest'],
            'iot': ['sensor', 'device', 'monitor', 'data', 'telemetry', 'iot', 'smart', 'automation'],
            'ai_ml': ['model', 'prediction', 'training', 'algorithm', 'neural', 'ai', 'ml', 'machine learning'],
            'cms': ['content', 'article', 'page', 'media', 'publish', 'blog', 'news', 'editor'],
            'api_service': ['api', 'service', 'endpoint', 'microservice', 'rest', 'graphql', 'webhook']
        }

        found_domains = []
        for domain, keywords in domain_keywords.items():
            score = 0
            for keyword in keywords:
                if self._search_keyword_in_files(keyword):
                    score += 1
            if score >= 2:
                found_domains.append((domain, score))

        if found_domains:
            found_domains.sort(key=lambda x: x[1], reverse=True)
            self.analysis_result['business_domain'] = found_domains[0][0]
        else:
            self.analysis_result['business_domain'] = 'web_application'

    def _extract_models(self):
        """ë°ì´í„° ëª¨ë¸ ì¶”ì¶œ"""
        models = {}

        if self._has_file('backend/requirements.txt') or self._has_file('requirements.txt'):
            models_paths = [
                self.project_root / 'backend' / 'app' / 'models',
                self.project_root / 'app' / 'models',
                self.project_root / 'models'
            ]

            for models_path in models_paths:
                if models_path.exists():
                    for model_file in models_path.glob('*.py'):
                        if model_file.name == '__init__.py':
                            continue
                        model_name = model_file.stem
                        models[model_name] = self._parse_python_model(model_file)
                    break

        self.analysis_result['models'] = models

    def _parse_python_model(self, model_file: Path) -> Dict:
        """Python ëª¨ë¸ íŒŒì¼ íŒŒì‹±"""
        try:
            with open(model_file, 'r', encoding='utf-8') as f:
                content = f.read()

            model_info = {
                'table_name': '',
                'fields': [],
                'relationships': [],
                'patterns': []
            }

            # ê°„ë‹¨í•œ ì •ê·œì‹ ê¸°ë°˜ íŒŒì‹±
            table_match = re.search(r'__tablename__\s*=\s*["\']([^"\']+)["\']', content)
            if table_match:
                model_info['table_name'] = table_match.group(1)

            column_pattern = r'(\w+)\s*=\s*Column\([^)]+\)'
            columns = re.findall(column_pattern, content)
            model_info['fields'] = columns

            if 'relationship' in content:
                model_info['patterns'].append('ORM Relationships')
            if 'ForeignKey' in content:
                model_info['patterns'].append('Foreign Keys')
            if 'primary_key' in content:
                model_info['patterns'].append('Primary Key')

            return model_info
        except Exception as e:
            print(f"ëª¨ë¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {'table_name': '', 'fields': [], 'relationships': [], 'patterns': []}

    def _extract_apis(self):
        """API ì—”ë“œí¬ì¸íŠ¸ ì¶”ì¶œ"""
        apis = {}

        if self._has_file('backend/requirements.txt') or self._has_file('requirements.txt'):
            routes_paths = [
                self.project_root / 'backend' / 'app' / 'routes',
                self.project_root / 'app' / 'routes',
                self.project_root / 'routes'
            ]

            for routes_path in routes_paths:
                if routes_path.exists():
                    for route_file in routes_path.glob('*.py'):
                        if route_file.name == '__init__.py':
                            continue
                        route_name = route_file.stem
                        apis[route_name] = self._parse_python_routes(route_file)
                    break

        self.analysis_result['apis'] = apis

    def _parse_python_routes(self, route_file: Path) -> List[Dict]:
        """Python ë¼ìš°íŠ¸ íŒŒì¼ íŒŒì‹±"""
        try:
            with open(route_file, 'r', encoding='utf-8') as f:
                content = f.read()

            endpoints = []

            route_pattern = r'@(?:router|app)\.(get|post|put|delete|patch)\(["\']([^"\']+)["\']\)\s*\n\s*(?:async\s+)?def\s+(\w+)'
            matches = re.findall(route_pattern, content, re.MULTILINE)

            for method, path, function_name in matches:
                endpoints.append({
                    'method': method.upper(),
                    'path': path,
                    'function_name': function_name,
                    'description': self._extract_function_docstring(content, function_name)
                })

            return endpoints
        except Exception as e:
            print(f"ë¼ìš°íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []

    def _extract_function_docstring(self, content: str, function_name: str) -> str:
        """í•¨ìˆ˜ docstring ì¶”ì¶œ"""
        pattern = rf'(?:async\s+)?def\s+{function_name}[^:]*:\s*\n\s*"""(.*?)"""'
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else ""

    def _extract_features(self):
        """í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŠ¥ ì¶”ì¶œ"""
        features = {}

        if self._has_file('frontend/package.json') or self._has_file('package.json'):
            app_paths = [
                self.project_root / 'frontend' / 'app',
                self.project_root / 'app',
                self.project_root / 'src'
            ]

            for app_path in app_paths:
                if app_path.exists():
                    for page_dir in app_path.iterdir():
                        if page_dir.is_dir() and not page_dir.name.startswith('.'):
                            page_name = page_dir.name
                            features[page_name] = {
                                'path': f'/{page_name}',
                                'description': self._extract_page_description(page_dir)
                            }
                    break

        self.analysis_result['features'] = features

    def _extract_page_description(self, page_dir: Path) -> str:
        """í˜ì´ì§€ ì„¤ëª… ì¶”ì¶œ"""
        page_files = ['page.js', 'page.jsx', 'page.ts', 'page.tsx', 'index.js', 'index.jsx']

        for page_file in page_files:
            if (page_dir / page_file).exists():
                try:
                    with open(page_dir / page_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if 'export default' in content:
                            return f"React ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ {page_dir.name} í˜ì´ì§€"
                        elif 'function' in content:
                            return f"JavaScript í•¨ìˆ˜ ê¸°ë°˜ {page_dir.name} í˜ì´ì§€"
                except Exception:
                    continue

        return f"ì›¹ í˜ì´ì§€: {page_dir.name}"

    def _calculate_confidence(self):
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.0

        if self.analysis_result['project_type'] != 'unknown':
            confidence += 0.3

        tech_stack = self.analysis_result['tech_stack']
        if tech_stack['backend'].get('framework') != 'Unknown':
            confidence += 0.2
        if tech_stack['frontend'].get('framework') != 'Unknown':
            confidence += 0.2
        if tech_stack['database'].get('type') != 'Unknown':
            confidence += 0.1
        if tech_stack['infrastructure'].get('containerization') != 'None':
            confidence += 0.1

        if self.analysis_result['models']:
            confidence += 0.1
        if self.analysis_result['apis']:
            confidence += 0.1

        self.analysis_result['confidence'] = min(confidence, 1.0)

    def _search_keyword_in_files(self, keyword: str) -> bool:
        """íŒŒì¼ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        for file_path in self.project_root.rglob('*.py'):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    if keyword.lower() in f.read().lower():
                        return True
            except:
                continue
        return False

    def _search_in_file(self, file_path: str, keyword: str) -> bool:
        """íŠ¹ì • íŒŒì¼ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        try:
            with open(self.project_root / file_path, 'r', encoding='utf-8') as f:
                return keyword.lower() in f.read().lower()
        except:
            return False

    def _has_file(self, filename: str) -> bool:
        """íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return (self.project_root / filename).exists()

class PRDData(BaseModel):
    """PRD ë°ì´í„° êµ¬ì¡° ì •ì˜"""
    project_name: str = Field(description="í”„ë¡œì íŠ¸ëª…")
    vision: str = Field(description="ì œí’ˆ ë¹„ì „")
    core_values: List[str] = Field(description="í•µì‹¬ ê°€ì¹˜ ëª©ë¡")
    target_users: str = Field(description="íƒ€ê²Ÿ ì‚¬ìš©ì")
    key_features: List[str] = Field(description="í•µì‹¬ ê¸°ëŠ¥ ëª©ë¡")
    technical_architecture: str = Field(description="ê¸°ìˆ  ì•„í‚¤í…ì²˜ ì„¤ëª…")
    security_requirements: List[str] = Field(description="ë³´ì•ˆ ìš”êµ¬ì‚¬í•­")
    performance_requirements: List[str] = Field(description="ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­")
    deployment_strategy: str = Field(description="ë°°í¬ ì „ëµ")
    roadmap: List[str] = Field(description="ê°œë°œ ë¡œë“œë§µ")
    kpis: List[str] = Field(description="ì„±ê³µ ì§€í‘œ")

class AIPRDGenerator:
    """AI ê¸°ë°˜ PRD ìƒì„±ê¸° í´ë˜ìŠ¤"""

    def __init__(self, api_key: str = None):
        """AI PRD ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')

        if not self.api_key:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ --api-key ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            print("ğŸ’¡ OpenAI API í‚¤ë¥¼ ì–»ìœ¼ë ¤ë©´: https://platform.openai.com/api-keys")
            self.llm = None
        else:
            # OpenAI ëª¨ë¸ ì´ˆê¸°í™”
            self.llm = ChatOpenAI(
                model_name="gpt-3.5-turbo",
                temperature=0.7,
                openai_api_key=self.api_key
            )

            # ì¶œë ¥ íŒŒì„œ ì„¤ì •
            self.output_parser = PydanticOutputParser(pydantic_object=PRDData)

            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
            self.prompt_template = ChatPromptTemplate.from_messages([
                SystemMessage(content="""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì œí’ˆ ê¸°íšì(Product Manager)ì…ë‹ˆë‹¤.
ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ PRD(Product Requirements Document)ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ PRDë¥¼ ìƒì„±í•˜ì„¸ìš”:
- í”„ë¡œì íŠ¸ íƒ€ì…ê³¼ ê¸°ìˆ  ìŠ¤íƒ
- ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸
- ë°ì´í„° ëª¨ë¸ê³¼ API êµ¬ì¡°
- í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŠ¥

PRDëŠ” ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”:
1. ì œí’ˆëª…ê³¼ ë¹„ì „
2. í•µì‹¬ ê°€ì¹˜ (3-4ê°œ)
3. íƒ€ê²Ÿ ì‚¬ìš©ì
4. í•µì‹¬ ê¸°ëŠ¥ (5-7ê°œ)
5. ê¸°ìˆ  ì•„í‚¤í…ì²˜ ì„¤ëª…
6. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
7. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
8. ë°°í¬ ì „ëµ
9. ê°œë°œ ë¡œë“œë§µ (3ë‹¨ê³„)
10. ì„±ê³µ ì§€í‘œ (KPI)

ê° ì„¹ì…˜ì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""),
                HumanMessage(content="""ë‹¤ìŒ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ PRDë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

í”„ë¡œì íŠ¸ ì •ë³´:
- í”„ë¡œì íŠ¸ íƒ€ì…: {project_type}
- ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸: {business_domain}
- ë¶„ì„ ì‹ ë¢°ë„: {confidence}

ê¸°ìˆ  ìŠ¤íƒ:
ë°±ì—”ë“œ: {backend_info}
í”„ë¡ íŠ¸ì—”ë“œ: {frontend_info}
ë°ì´í„°ë² ì´ìŠ¤: {database_info}
ì¸í”„ë¼: {infrastructure_info}

ë°ì´í„° ëª¨ë¸: {models_info}
API ì—”ë“œí¬ì¸íŠ¸: {apis_info}
í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŠ¥: {features_info}

{format_instructions}""")
            ])

            # LLM ì²´ì¸ ì„¤ì •
            self.chain = LLMChain(
                llm=self.llm,
                prompt=self.prompt_template,
                output_parser=self.output_parser
            )

    def generate_prd(self, analysis_result: Dict) -> str:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ PRD ìƒì„±"""
        if not self.llm:
            return self._generate_fallback_prd(analysis_result)

        try:
            # ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            formatted_data = self._format_analysis_data(analysis_result)

            # AIë¥¼ ì‚¬ìš©í•˜ì—¬ PRD ë°ì´í„° ìƒì„±
            result = self.chain.run(
                project_type=analysis_result.get('project_type', 'unknown'),
                business_domain=analysis_result.get('business_domain', 'unknown'),
                confidence=f"{analysis_result.get('confidence', 0.0):.1%}",
                backend_info=formatted_data['backend'],
                frontend_info=formatted_data['frontend'],
                database_info=formatted_data['database'],
                infrastructure_info=formatted_data['infrastructure'],
                models_info=formatted_data['models'],
                apis_info=formatted_data['apis'],
                features_info=formatted_data['features'],
                format_instructions=self.output_parser.get_format_instructions()
            )

            # ìƒì„±ëœ PRD ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
            return self._convert_to_markdown(result, analysis_result)

        except Exception as e:
            print(f"AI PRD ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_prd(analysis_result)

    def _format_analysis_data(self, analysis_result: Dict) -> Dict:
        """ë¶„ì„ ê²°ê³¼ë¥¼ AI í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        tech_stack = analysis_result.get('tech_stack', {})

        return {
            'backend': f"ì–¸ì–´: {tech_stack.get('backend', {}).get('language', 'Unknown')}, í”„ë ˆì„ì›Œí¬: {tech_stack.get('backend', {}).get('framework', 'Unknown')}, íŒ¨í„´: {', '.join(tech_stack.get('backend', {}).get('patterns', []))}",
            'frontend': f"í”„ë ˆì„ì›Œí¬: {tech_stack.get('frontend', {}).get('framework', 'Unknown')}, UI ë¼ì´ë¸ŒëŸ¬ë¦¬: {tech_stack.get('frontend', {}).get('ui_library', 'Unknown')}, íŒ¨í„´: {', '.join(tech_stack.get('frontend', {}).get('patterns', []))}",
            'database': f"íƒ€ì…: {tech_stack.get('database', {}).get('type', 'Unknown')}, ORM: {tech_stack.get('database', {}).get('orm', 'Unknown')}, íŒ¨í„´: {', '.join(tech_stack.get('database', {}).get('patterns', []))}",
            'infrastructure': f"ì»¨í…Œì´ë„ˆí™”: {tech_stack.get('infrastructure', {}).get('containerization', 'None')}, ë°°í¬: {tech_stack.get('infrastructure', {}).get('deployment', 'Unknown')}, ëª¨ë‹ˆí„°ë§: {tech_stack.get('infrastructure', {}).get('monitoring', 'None')}",
            'models': str(analysis_result.get('models', {})),
            'apis': str(analysis_result.get('apis', {})),
            'features': str(analysis_result.get('features', {}))
        }

    def _convert_to_markdown(self, prd_data: PRDData, analysis_result: Dict) -> str:
        """PRD ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        current_date = datetime.now().strftime('%Y-%m-%d')

        return f"""# {prd_data.project_name} PRD (Product Requirements Document)

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ë²„ì „**: v1.0
- **ì‘ì„±ì¼**: {current_date}
- **ì‘ì„±ì**: AI PRD Generator (LangChain + OpenAI)
- **ë§ˆì§€ë§‰ ìˆ˜ì •**: {current_date}
- **í”„ë¡œì íŠ¸ íƒ€ì…**: {analysis_result.get('project_type', 'unknown')}
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸**: {analysis_result.get('business_domain', 'unknown')}
- **ë¶„ì„ ì‹ ë¢°ë„**: {analysis_result.get('confidence', 0.0):.1%}

## ğŸ¯ 1. ì œí’ˆ ê°œìš”
### 1.1 ì œí’ˆëª…
{prd_data.project_name}

### 1.2 ì œí’ˆ ë¹„ì „
{prd_data.vision}

### 1.3 í•µì‹¬ ê°€ì¹˜
{chr(10).join([f"- {value}" for value in prd_data.core_values])}

### 1.4 íƒ€ê²Ÿ ì‚¬ìš©ì
{prd_data.target_users}

## ğŸ—ï¸ 2. ê¸°ìˆ  ì•„í‚¤í…ì²˜
{prd_data.technical_architecture}

## âš™ï¸ 3. í•µì‹¬ ê¸°ëŠ¥
{chr(10).join([f"### 3.{i+1} {feature}" for i, feature in enumerate(prd_data.key_features)])}

## ğŸ”’ 4. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
{chr(10).join([f"- {req}" for req in prd_data.security_requirements])}

## ğŸ“ˆ 5. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
{chr(10).join([f"- {req}" for req in prd_data.performance_requirements])}

## ğŸš€ 6. ë°°í¬ ì „ëµ
{prd_data.deployment_strategy}

## ğŸ“… 7. ê°œë°œ ë¡œë“œë§µ
{chr(10).join([f"### 7.{i+1} Phase {i+1}" for i, phase in enumerate(prd_data.roadmap)])}

## ğŸ“Š 8. ì„±ê³µ ì§€í‘œ (KPI)
{chr(10).join([f"- {kpi}" for kpi in prd_data.kpis])}

## ğŸ“ 9. ë¶€ë¡
### 9.1 ìš©ì–´ ì •ì˜
- **API**: Application Programming Interface
- **ORM**: Object-Relational Mapping
- **JWT**: JSON Web Token
- **CORS**: Cross-Origin Resource Sharing

### 9.2 ì°¸ê³  ìë£Œ
- í”„ë¡œì íŠ¸ ê´€ë ¨ ê³µì‹ ë¬¸ì„œ
- ì‚¬ìš©ëœ ê¸°ìˆ  ìŠ¤íƒ ê³µì‹ ë¬¸ì„œ
- ê´€ë ¨ í‘œì¤€ ë° ê·œê²©

### 9.3 ë³€ê²½ ì´ë ¥
| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ | ì‘ì„±ì |
|------|------|----------|--------|
| v1.0 | {current_date} | ì´ˆê¸° ë²„ì „ | AI PRD Generator |
"""

    def _generate_fallback_prd(self, analysis_result: Dict) -> str:
        """AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ë•Œ í´ë°± PRD ìƒì„±"""
        current_date = datetime.now().strftime('%Y-%m-%d')

        return f"""# Coding Quiz Platform PRD (Product Requirements Document)

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ë²„ì „**: v1.0
- **ì‘ì„±ì¼**: {current_date}
- **ì‘ì„±ì**: AI PRD Generator (Fallback Mode)
- **ë§ˆì§€ë§‰ ìˆ˜ì •**: {current_date}
- **í”„ë¡œì íŠ¸ íƒ€ì…**: {analysis_result.get('project_type', 'unknown')}
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸**: {analysis_result.get('business_domain', 'unknown')}
- **ë¶„ì„ ì‹ ë¢°ë„**: {analysis_result.get('confidence', 0.0):.1%}

## âš ï¸ AI ëª¨ë“œ ë¹„í™œì„±í™”
OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ PRD í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
AI ê¸°ë°˜ PRD ìƒì„±ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.

## ğŸ¯ 1. ì œí’ˆ ê°œìš”
### 1.1 ì œí’ˆëª…
Coding Quiz Platform

### 1.2 ì œí’ˆ ë¹„ì „
í•™ìŠµì ì¤‘ì‹¬ì˜ êµìœ¡ í”Œë«í¼ìœ¼ë¡œ íš¨ê³¼ì ì¸ í•™ìŠµ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

### 1.3 í•µì‹¬ ê°€ì¹˜
- **ì‚¬ìš©ì ì¤‘ì‹¬**: ì‚¬ìš©ì ê²½í—˜ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤
- **ì•ˆì •ì„±**: ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ ì œê³µ
- **í™•ì¥ì„±**: ë¯¸ë˜ ì„±ì¥ì— ëŒ€ë¹„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- **ë³´ì•ˆ**: ì‚¬ìš©ì ë°ì´í„°ì™€ ì‹œìŠ¤í…œì˜ ë³´ì•ˆ ë³´ì¥

### 1.4 íƒ€ê²Ÿ ì‚¬ìš©ì
í•™ìŠµì, êµìœ¡ì, êµìœ¡ ê¸°ê´€

## ğŸ—ï¸ 2. ê¸°ìˆ  ìŠ¤íƒ
### 2.1 ë°±ì—”ë“œ
- **Language**: Python
- **Framework**: FastAPI
- **Patterns**: ORM, JWT Authentication, Password Hashing

### 2.2 í”„ë¡ íŠ¸ì—”ë“œ
- **Framework**: Next.js
- **UI Library**: React Bootstrap
- **Patterns**: SSR/SSG, HTTP Client

### 2.3 ë°ì´í„°ë² ì´ìŠ¤
- **Type**: PostgreSQL
- **ORM**: SQLAlchemy

## âš™ï¸ 3. í•µì‹¬ ê¸°ëŠ¥
### 3.1 ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ
- JWT ê¸°ë°˜ ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

### 3.2 í€´ì¦ˆ ì‹œìŠ¤í…œ
- ì¹´í…Œê³ ë¦¬ë³„ í€´ì¦ˆ ì œê³µ ë° ì‹¤ì‹œê°„ ì±„ì 

### 3.3 ë­í‚¹ ì‹œìŠ¤í…œ
- ì‚¬ìš©ìë³„ ì ìˆ˜ ê¸°ë°˜ ë­í‚¹ ì œê³µ

### 3.4 ì½˜í…ì¸  ê´€ë¦¬ ì‹œìŠ¤í…œ
- CSV íŒŒì¼ ê¸°ë°˜ ë¬¸ì œ ë°ì´í„° ê´€ë¦¬

## ğŸ”’ 4. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
- JWT í† í° ê¸°ë°˜ ì¸ì¦
- ë¹„ë°€ë²ˆí˜¸ í•´ì‹±
- SQL Injection ë°©ì§€
- XSS ë°©ì§€
- CORS ì •ì±… ì ìš©

## ğŸ“ˆ 5. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
- API ì‘ë‹µ ì‹œê°„: 200ms ì´í•˜
- í˜ì´ì§€ ë¡œë”© ì‹œê°„: 2ì´ˆ ì´í•˜
- ë™ì‹œ ì‚¬ìš©ì: 100ëª… ì´ìƒ ì§€ì›

## ğŸš€ 6. ë°°í¬ ì „ëµ
- Docker ì»¨í…Œì´ë„ˆí™”
- í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬
- CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

## ğŸ“… 7. ê°œë°œ ë¡œë“œë§µ
### 7.1 Phase 1 (1-3ê°œì›”)
- ê¸°ë³¸ í€´ì¦ˆ ê¸°ëŠ¥ ì™„ì„±
- ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•

### 7.2 Phase 2 (3-6ê°œì›”)
- ë­í‚¹ ì‹œìŠ¤í…œ êµ¬í˜„
- ì„±ëŠ¥ ìµœì í™”

### 7.3 Phase 3 (6-12ê°œì›”)
- ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€
- ëª¨ë°”ì¼ ì§€ì›

## ğŸ“Š 8. ì„±ê³µ ì§€í‘œ (KPI)
- ì¼ì¼ í™œì„± ì‚¬ìš©ì (DAU)
- ì›”ê°„ í™œì„± ì‚¬ìš©ì (MAU)
- ì‚¬ìš©ì ìœ ì§€ìœ¨
- í€´ì¦ˆ ì™„ë£Œìœ¨
- í‰ê·  ì„¸ì…˜ ì‹œê°„

## ğŸ“ 9. ë¶€ë¡
### 9.1 ìš©ì–´ ì •ì˜
- **API**: Application Programming Interface
- **ORM**: Object-Relational Mapping
- **JWT**: JSON Web Token
- **CORS**: Cross-Origin Resource Sharing

### 9.2 ì°¸ê³  ìë£Œ
- FastAPI ê³µì‹ ë¬¸ì„œ
- Next.js ê³µì‹ ë¬¸ì„œ
- SQLAlchemy ê³µì‹ ë¬¸ì„œ

### 9.3 ë³€ê²½ ì´ë ¥
| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ | ì‘ì„±ì |
|------|------|----------|--------|
| v1.0 | {current_date} | ì´ˆê¸° ë²„ì „ | AI PRD Generator |
"""

def main():
    parser = argparse.ArgumentParser(description='AI ê¸°ë°˜ PRD ìƒì„±ê¸°')
    parser.add_argument('--project-root', default='.', help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output', default='AI_PRD.md', help='ì¶œë ¥ íŒŒì¼ëª…')
    parser.add_argument('--api-key', help='OpenAI API í‚¤')

    args = parser.parse_args()

    # ì½”ë“œë² ì´ìŠ¤ ë¶„ì„
    analyzer = CodebaseAnalyzer(args.project_root)
    analyzer.analyze_project()

    # AI PRD ìƒì„±
    ai_generator = AIPRDGenerator(args.api_key)
    prd_content = ai_generator.generate_prd(analyzer.analysis_result)

    # íŒŒì¼ ì €ì¥
    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(prd_content)

    print(f"âœ… AI PRDê°€ {args.output}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š í”„ë¡œì íŠ¸ íƒ€ì…: {analyzer.analysis_result['project_type']}")
    print(f"ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸: {analyzer.analysis_result['business_domain']}")
    print(f"ğŸ¯ ë¶„ì„ ì‹ ë¢°ë„: {analyzer.analysis_result['confidence']:.1%}")
    print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {len(prd_content)} ë¬¸ì")

    if not ai_generator.api_key:
        print("\nğŸ’¡ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
        print("   export OPENAI_API_KEY='your-api-key-here'")
        print("   ë˜ëŠ” --api-key ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
